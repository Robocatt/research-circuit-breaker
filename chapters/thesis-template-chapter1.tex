% \usepackage{longtable}
% \usepackage{tabularx}
% \usepackage{ltablex} 
\chapter{Аналитический обзор современных решений для обеспечения отказоустойчивости в микросервисных архитектурах.}
\label{chapter1}



%Большие отсупы --- это хорошо. Облегчает чтение длинных <<простыней>> текста
% \section{Общий анализ отказоустойчивости в микросервисах и паттернов}


\textbf{Аннотация. } \textit{В разделе обобщаются современные подходы к обеспечению отказоустойчивости микросервисных архитектур с учётом их специфики и типичных рисков. Анализируются характерные проблемы надёжности распределённых сервисов и архитектурные паттерны (Circuit Breaker, Bulkhead), локализующие влияние отказов. Рассматриваются инфраструктурные решения, включая контейнеризацию и платформы оркестрации (Docker, Kubernetes), а также сетевые решения уровня service mesh. Приводится сравнительный анализ популярных реализаций service mesh (Istio, Linkerd, Consul, Kuma) с обоснованием выбора Istio для практического применения. Рассматриваются методы оценки эффективности реализации: нагрузочное тестирование, трассировка. Сделан вывод о необходимости комплексного подхода, объединяющего паттерны, инфраструктуру и инструменты тестирования для достижения заданного уровня надёжности.}

Микросервисные системы предъявляют особые требования к обеспечению надёжности и устойчивости к отказам. В данном разделе обобщаются современные методы и инструменты, которые позволяют достичь высокой отказоустойчивости микросервисной архитектуры. Рассматриваются характерные проблемы надёжности распределённых сервисов и анализируются архитектурные паттерны, повышающие устойчивость (в том числе сравнение паттернов Circuit Breaker, Bulkhead и др.). Анализируются средства инфраструктуры – контейнеризации (Docker/Kubernetes) и сетевые решения (service mesh) – и их роли в построении отказоустойчивых микросервисов. Далее, проведён сравнительный обзор популярных реализаций service mesh: Istio, Linkerd, Consul, Kuma. Затем, описываются методы тестирования отказоустойчивости: инструменты для нагрузочного тестирования такие как k6, трассировки распределённых запросов (Jaeger).

\section{Анализ архитектурных паттернов, обеспечивающих отказоустойчивость.}
% claude аннотация по тексту 
\textbf{Аннотация. }\textit{В отказоустойчивых системах сбои отдельных компонентов не должны приводить к недоступности всего приложения. Для достижения этого в микросервисной архитектуре используются специальные шаблоны проектирования (паттерны) надёжности. Два ключевых паттерна – это «Circuit Breaker» и «Bulkhead». Circuit Breaker отслеживает выполнение удалённых запросов и при накоплении ошибок автоматически «размыкает цепь», предотвращая дальнейшие вызовы проблемного сервиса на время его восстановления. Bulkhead изолирует ресурсы (пулы потоков, подключения) для разных частей системы, не позволяя отказу или перегрузке в одном сервисе использовать все общие ресурсы и нарушить работу других. В данном подразделе анализируется механизм действия этих паттернов и их применение для предотвращения каскадных отказов. Также кратко рассматриваются дополнительные приёмы повышения надёжности – повторные попытки (Retry), таймауты и резервные ответы (Fallback). В итоге подчёркивается, что сочетание грамотной архитектуры (паттерны отказоустойчивости) с правильной реализацией позволяет существенно повысить устойчивость сложных распределённых систем.}

В микросервисной архитектуре отказ одного сервиса способен вызвать цепочку проблем во всей системе – эффект каскадного сбоя. Чтобы локализовать сбои и предотвратить их распространение, применяются шаблоны отказоустойчивости. \textbf{Circuit Breaker}  является одним из наиболее распространённых решений для повышения надёжности сервисов \cite{Newman2021}. Его идея позаимствована из электротехники: подобно автоматическому предохранителю, он разрывает цепь вызовов при обнаружении постоянных ошибок во взаимодействии сервисов. Реализация данного паттерна предусматривает мониторинг удалённых вызовов: если за заданный интервал накопилось определённое число неудач (исключений, таймаутов), Circuit Breaker переводится в состояние «Open» и начинает блокировать дальнейшие запросы к проблемному сервису, сразу возвращая ошибку или резервный ответ. Через некоторое время (период полуоткрытого состояния Half-Open) размыкатель пропускает пробный запрос, и при успешном ответе замыкается обратно (состояние «Closed»), возобновляя нормальную работу; если же ошибка сохраняется – цикл повторяется. Таким образом, данный паттерн позволяет избегать бесполезной нагрузки на зависимый сервис, давая ему время восстановиться, и предотвращает занятия потоков ожиданием недоступного ресурса \cite{Punithavathy2024}. Практически, использование Circuit Breaker снижает риск обрушения всей системы из-за одного сбойного компонента.

Другим важным шаблоном является паттерн \textbf{Bulkhead}. Этот шаблон предлагает изолировать ресурсы для отдельных сервисов или групп запросов. Например, можно выделить независимые пулы потоков или подключений к БД для каждого микросервиса. В результате отказ или задержка в одном компоненте потребляет ресурсы только своего пула и не сможет повлиять на всю систему. Bulkhead-паттерн повышает устойчивость за счёт ограничения области воздействия сбоя: сбойный сервис исчерпает лишь свой выделенный лимит потоков/соединений, но остальные сервисы продолжат работать штатно \cite{IEEE2023}. На практике Bulkhead часто реализуется средствами контейнерной оркестрации или специальных библиотек – например, выделением отдельного пула потоков в контейнере для каждого клиента. В сочетании с Circuit Breaker, Bulkhead образует многослойную защиту: размыкатель быстро отсекает проблемные вызовы, а Bulkhead обеспечивает изоляцию ресурсов и предотвращает каскадное распространение отказов в системе, локализуя сбои и минимизируя их влияние на остальные компоненты. По данным исследований, паттерн Circuit Breaker способен снизить долю ошибок почти на 60\%, а Bulkhead повысить общую доступность сервисов примерно на 10\% \cite{IEEE2023}.

Помимо указанных двух паттернов, в арсенале архитектуры микросервисов имеются и другие приёмы повышения устойчивости. Часто применяется паттерн \textbf{Retry} (повторный запрос) --- автоматическая повторная попытка вызова внешнего сервиса при неудаче, обычно с экспоненциальной задержкой между попытками, чтобы не создать дополнительную нагрузку. Retry полезен при кратковременных сбоях (транзиентных ошибках), но должен сочетаться с ограничением числа попыток и с Circuit Breaker, чтобы повторные вызовы не усугубляли ситуацию при длительной недоступности сервиса \cite{Punithavathy2024}. Ещё один важный механизм --- \textbf{Timeout} (таймауты на вызовы): если внешний запрос не отвечает за разумное время, он прерывается, что освобождает занятые ресурсы. В связке с таймаутами обычно используются Fallback-методы --- альтернативные действия при сбое внешнего сервиса (например, возврат кэшированного значения, дефолтного ответа или деградация функциональности). Такие меры позволяют системе деградировать gracefully, без резкого отказа \cite{Nygard2018}.

Комплексное применение данных паттернов доказало свою эффективность на практике. В частности, опыты, проведённые Netflix при внедрении библиотеки Hystrix, показали существенное снижение числа инцидентов, связанных с каскадными сбоями. Эти паттерны стали настолько важны, что современные фреймворки (например, Resilience4j для Java) и сервис-меш технологии (см. подраздел 1.2) поддерживают их «из коробки». Таким образом, архитектурные решения в виде Circuit Breaker, Bulkhead и сопутствующих им шаблонов (Retry, Timeout, Fallback) являются важнейшими компонентами обеспечения отказоустойчивости микросервисных приложений.

Паттерн Circuit Breaker является ключевым механизмом обеспечения отказоустойчивости микросервисной архитектуры, так как он своевременно обнаруживает сбои и локализует их, предотвращая цепную реакцию отказов в системе. Выбор этого паттерна для исследования обусловлен его доказанной эффективностью в снижении риска системных сбоев и возможности изолировать неисправные компоненты, что существенно повышает общую стабильность распределённых приложений. 

\section{Анализ возможностей контейнеризации для повышения надежности микросервисной архитектуры}
% claude аннотация по тексту 
\textbf{Аннотация. }\textit{Рассмотрено влияние контейнеризации и оркестрации на отказоустойчивость облачных приложений. Проведен анализ использования Docker для создания лёгкой изоляции микросервисов, благодаря чему будет снижена вероятность ошибок окружения. Проведено исследование автоматизированного управления состоянием сервисов с помощью Kubernetes. Проанализированы механизмы оркестраторов, такие как перезапуск контейнеров и перенос подов. Подчеркнута роль Kubernetes как «операционной системы» для кластера и обеспечения надежности. Изучено применение service mesh как дополнительного слоя для управления межсервисными взаимодействиями. Упоминается о различных решениях service-mesh: Istio, Linkerd, Consul Connect и Kuma. Сделан акцент на многоуровневом подходе к созданию отказоустойчивых микросервисных систем}

Контейнеризация и оркестрация внесли решающий вклад в повышение отказоустойчивости облачных приложений. Контейнеры предоставляют лёгковесную изоляцию сервисов, позволяя каждому микросервису работать в унифицированной среде с чётко определёнными зависимостями. Это снижает вероятность ошибок окружения и облегчает масштабирование. Более того, запуск сервиса в виде контейнера существенно ускоряет его перезапуск при сбое, позволяет автоматизировать повторный запуск.

Ключевым инструментом управления контейнеризированными микросервисами является \textbf{Kubernetes} – платформа оркестрации. Kubernetes автоматически следит за состоянием приложений и применяет стратегии self-healing: при падении контейнера оркестратор перезапускает его, при отключении узла – переносит поды на работоспособные узлы, а при повышении нагрузки – может автоматически масштабировать реплики сервисов. Тем самым обеспечивается базовая устойчивость системы к аппаратным и программным сбоям без вмешательства администратора. Таким образом, оркестратор действует как «операционная система» для кластера, гарантируя, что заданное число экземпляров каждого сервиса всегда работает, несмотря на возможные локальные сбои. Существуют различные реализации Kubernetes. Для ресурсов с ограниченными вычислительными ресурсами разработаны облегчённые дистрибутивы Kubernetes, такие как \textbf{K3s}. Данная реализация представляет собой полностью совместимую с Kubernetes версию оркестратора, упакованную в один исполняемый файл размером менее 100 МБ \cite{hoffman2023k3s}. Использование K3s позволяет вынести микросервисную инфраструктуру за пределы крупных датацентров, обеспечивая при этом механизмы отказоустойчивости Kubernetes в малых масштабах.

Однако одного механизма перезапуска сервисов недостаточно для комплексной надёжности: необходимо обеспечить устойчивость между сервисами, на уровне их взаимодействий. Для обеспечения такой устойчивости, была разработана концепция \textbf{service mesh}. Service mesh – это дополнительный коммуникационный слой поверх сетевого взаимодействия микросервисов. Он решает задачи обнаружения сервисов, балансировки нагрузки, шифрования трафика, а также реализации шаблонов устойчивости (таких как circuit breaking, retries) на уровне сети. Типичная архитектура service mesh включает \textit{data plane} (сетевые прокси рядом с каждым сервисом) и \textit{control plane} (централизованный диспетчер, управляющий правилами маршрутизации и сбора телеметрии). В результате каждый межсервисный вызов проходит через локальный прокси, который может выполнить необходимую логику: например, перенаправить запрос по другому маршруту, если основной сервис недоступен, зашифровать соединение, или прервать попытки связи при повторяющихся неудачах (circuit breaker на уровне service mesh). Таким образом, применение mesh-инфраструктуры позволяет централизованно реализовать множество механизмов обеспечения надежности, которые в ином случае пришлось бы интегрировать непосредственно в код каждого отдельного сервиса. Исследования отмечают, что service mesh позволяет стандартизировать и упростить коммуникации: все вызовы проходят единообразную обработку, что снижает вероятность непредусмотренных отказов\cite{palavesam2025}. Примеры реализаций service mesh включают \textbf{Istio}, \textbf{Linkerd}, \textbf{Consul Connect} и \textbf{Kuma} (их сравнительный анализ приведён в подразделе 1.3). Общая цель у них одна – надёжная доставка запросов между микросервисами\cite{farkiani2022}, но подходы различаются.

Service mesh тесно интегрируется с оркестратором: например, в Kubernetes прокси-меш обычно развёртываются как sidecar-контейнеры внутри тех же подов, что и основные сервисы. Такая интеграция позволяет Kubernetes автоматически внедрять mesh-политику при масштабировании или перезапуске сервисов. Таким образом, наблюдается эффективное взаимодействие компонентов системы: Kubernetes обеспечивает физическую устойчивость функционирования сервисов (их запуск, перезапуск и распределение), а mesh-слой — логическую устойчивость коммуникаций посредством маршрутизации, повторных попыток и изоляции сбоев. Современные исследования подтверждают, что сочетание оркестрации и service mesh значительно повышает надёжность сложных систем\cite{palavesam2025}. Можно заключить, что для построения отказоустойчивых микросервисов требуется многоуровневый подход: устойчивость отдельных сервисов (за счёт контейнеризации и оркестрации) плюс устойчивость их взаимодействия (за счёт service mesh).

\section{Анализ современных service mesh решений}

\textbf{Аннотация. }\textit{Рассмотрены основные open-source реализации service mesh для Kubernetes, а именно Istio, Linkerd, Consul Connect и Kuma. Проведен подробный анализ архитектурных особенностей каждой системы, включая использование прокси и контроллеров. Особое внимание уделено функциональному сравнению возможностей, таких как маршрутизация, балансировка нагрузки и fault injection. Описываются также механизмы обеспечения безопасности, обеспечивающие автоматическую выдачу сертификатов шифрования и настройку политик доступа. Анализируются накладные расходы и производительность каждого решения, учитывая специфику распределенных систем. Обосновывается рассмотрение Istio, несмотря на повышенные требования к ресурсам.}


Разработчики Kubernetes-среды могут выбирать из нескольких open-source реализаций service mesh. Наиболее популярны следующие решения:

\begin{enumerate}
    \item \textbf{Istio} --- масштабируемый сервис-меш, изначально разработанный Google, IBM и RedHat (появился в 2017~г.). 
    
    \item \textbf{Linkerd} --- лёгкий mesh, ориентированный на простоту и высокую производительность. Изначально разработан компанией Buoyant, переписана на Rust.
    
    \item \textbf{Consul (Connect)} --- расширение популярной системы Consul от HashiCorp до полноценного service mesh. 
    
    \item \textbf{Kuma} --- относительно новое решение (разработано Kong Inc., открыто в 2020~г.), позиционируемое как «универсальный сервис-меш». 
\end{enumerate}
Для более наглядного сравнения основных характеристик рассмотренных mesh-решений приведём обобщённую таблицу (табл.~\ref{tab:meshes}). Здесь сопоставляются функциональные возможности, требования и сферы применения Istio, Linkerd, Consul и Kuma.

\begingroup
\small
\setlength{\tabcolsep}{4pt} % Reduce column spacing
\begin{longtable}{|p{2.6cm}|p{3.3cm}|p{3.3cm}|p{3.3cm}|p{3.3cm}|}
\caption{Сравнение популярных service mesh для Kubernetes} \label{tab:meshes} \\
\hline
\textbf{Аспект} & \textbf{Istio} & \textbf{Linkerd} & \textbf{Consul Connect} & \textbf{Kuma} \\
\hline
\endfirsthead

\multicolumn{5}{c}{\tablename\ \thetable{} -- Продолжение} \\
\hline
\textbf{Аспект} & \textbf{Istio} & \textbf{Linkerd} & \textbf{Consul Connect} & \textbf{Kuma} \\
\hline
\endhead

\hline \multicolumn{5}{r}{{Продолжение на следующей странице}} \\
\endfoot

\hline
\endlastfoot

\textbf{Архитектура и прокси} & 
Envoy sidecar; контроллер Istiod. Модульная архитектура (Pilot, Mixer в ранних версиях) & 
Специальный лёгкий proxy (Linkerd2-proxy) на Rust; минималистичный контроллер. Монолитная архитектура & 
Envoy sidecar (или собственный proxy), контроллер интегрирован в Consul server. Требует Consul-кластера & 
Envoy sidecar; control-plane Kuma (кластеризуемый). Архитектура похожа на Istio, но проще \\
\hline

\textbf{Функционал и трафик} & 
Широкий: маршрутизация, балансировка, mirroring, fault injection, паттерны отказоустойчивости. Поддержка шлюзов ingress/egress. & 
Базовые возможности: load balancing, service discovery, mTLS. Ограниченная настройка маршрутов. & 
Широкие возможности service discovery (KV-хранилище). Traffic management присутствует, но менее гибкий, чем в Istio & 
Основной набор: трассировка, балансировка, маршрутизация, политики отказов, поддержка нескольких mesh. Мультизональность. \\
\hline

\textbf{Безопасность} & 
Полноценная инфраструктура: автовыдача сертификатов, mTLS, детальные настройки авторизации (RBAC, политики доступа) & 
mTLS по умолчанию для всех соединений. Нет встроенной сложной авторизации (интеграция с K8s RBAC) & 
mTLS через собственный CA Consul, гибкие политики «Intentions». Централизованное управление ACL & 
mTLS встроен (встроенный/внешний CA), политики доступа. Глобальные политики безопасности между зонами \\
\hline

\textbf{Произво\-ди\-тель\-ность} & 
Высокий overhead Envoy (CPU/память в 2–3 раза выше). Задержки под нагрузкой\cite{bremler2024performance}, хорошая масштабируемость & 
Минимальный overhead (быстрый proxy, мало ресурсов). Незначительные задержки. Эффективен при большом числе сервисов & 
Умеренные накладные расходы. Дополнительный ресурс на Consul-сервер. При >1000 сервисов Consul может стать узким местом & 
Сопоставимо с Istio. Контрольная плоскость лёгкая. Оптимизирован для распределённых сред \\
\hline


\textbf{Мульти\-клас\-тер\-ность
} & 
Поддерживается (multi-mesh/federation) — сложная настройка. Ориентирован на K8s; VM требуют доп. компонентов & 
Экспериментальное расширение Multi-Cluster. За пределами K8s не работает (только соединяет кластеры K8s) & 
Спроектирован для multi-datacenter. Легко соединяет кластеры и VM. Отличен для гибридных облаков & 
Концепция Zones: объединяет множество K8s-кластеров и других нод. Гибко работает в гибридных средах \\
\hline
\end{longtable}
\endgroup

Из таблицы видно, что \textbf{Istio} предлагает наибольшие возможности в плане управления трафиком и политик, но в то же время требует больше ресурсов и усилий на сопровождение. \textbf{Linkerd} наиболее лёгок и прост, что делает его привлекательным для небольших команд или в ситуациях, где дополнительные возможности mesh не столь востребованы. \textbf{Consul} выгодно отличается способностью соединять разные среды (не только Kubernetes), однако добавляет сложность развёртывания отдельного Consul-кластера. \textbf{Kuma} стремится сочетать преимущества обоих подходов – универсальность Consul с относительной простотой Linkerd.

В контексте данной работы выбор сделан в пользу \textbf{Istio}. Во-первых, как отмечается в исследованиях, Istio остаётся наиболее функционально насыщенной и гибкой платформой​ \cite{palavesam2025}, которая особенно эффективна в крупных масштабируемых системах. Во-вторых, нас интересует реализация паттерна Circuit Breaker и других механизмов отказоустойчивости на уровне service mesh – Istio предоставляет развитые средства для этого. Таким образом, несмотря на издержки в сложности, Istio представляется оптимальным выбором для изучения и реализации отказоустойчивой микросервисной архитектуры в рамках Kubernetes.

\section{Анализ инструментов и типов тестирования микросервисных архитектур.}

\textbf{Аннотация. }\textit{Приведено сравнительное исследование open-source инструментов нагрузочного тестирования, включая Gatling, Locust и k6, с анализом их сильных и слабых сторон. Разработана методика оценки производительности микросервисов посредством анализа и выбора тестов. Отражена архитектура модуля нагрузочного тестирования, реализованного с использованием k6, что позволяет генерировать значительную нагрузку при низких накладных расходах. Разработан модуль распределенного трассирования с использованием Jaeger, обеспечивающий сбор и визуализацию метрик, задержек и ошибок. Проведен анализ альтернативных систем трассировки, включая Zipkin и OpenTelemetry Collector, с акцентом на модульную и масштабируемую архитектуру Jaeger.}


Нагрузочное тестирование микросервисов можно проводить с помощью различных open-source инструментов, среди которых Gatling, Locust, k6 и др. Каждый из них имеет свои преимущества и недостатки, которые стоит учитывать при выборе для тестирования.
\begin{enumerate}
\item Gatling – высокопроизводительный инструмент для тестирования, разработанный на Scala. Он эффективно генерирует нагрузку даже при тысячах виртуальных пользователей, сохраняя низкую нагрузку на саму систему тестирования. Детализированные отчёты и графики помогают проводить глубокий анализ результатов. Недостатком является необходимость знания Scala и функционального программирования.

\item Locust – инструмент на Python, который позволяет описывать сценарии тестирования с использованием асинхронного подхода. Это делает его масштабируемым и гибким: поведение пользователей можно задавать программно, что удобно для сложных сценариев. Интеграция с CI/CD и возможность распределённых тестов – дополнительные плюсы. Однако встроенные средства визуализации менее развиты, и для полноценного анализа результатов могут потребоваться дополнительные инструменты.

\item k6 – современный инструмент для тестирования API и микросервисов, реализованный на Go с использованием JavaScript для описания сценариев. Он характеризуется низкими накладными расходами и эффективным использованием ресурсов, что позволяет генерировать значительную нагрузку. Прямая интеграция с системами мониторингаи возможность автоматизированного запуска в CI/CD делают его привлекательным для современных веб-сервисов. Основное ограничение – поддержка в основном HTTP/HTTPS и WebSocket, что может не подойти для тестирования специфических протоколов.
\end{enumerate}
Проанализировав перечисленные решения, в данном исследовании выбор сделан в пользу k6 как основного инструмента нагрузочного тестирования. Это обусловлено несколькими факторами. Во-первых, сценарии на JavaScript упрощают разработку тестов. Во-вторых, k6 легко интегрируется с инфраструктурой мониторинга, засчет удобного и быстроговывода метрик. В-третьих, низкая нагрузка самого инструмента на систему позволяет проводить более чистые эксперименты.

Нагрузочное тестирование включает несколько типов тестов, каждое из которых позволяет оценить разные аспекты производительности системы. К основным относятся:
\begin{enumerate}
    \item Нагрузочный тест (Load Test): проверяет работу сервиса при постепенном увеличении числа запросов или виртуальных пользователей, моделируя реальный рост трафика.

    \item Стресс-тест (Stress Test): определяет пределы устойчивости системы, подвергая её нагрузке, значительно превышающей номинальную.

    \item Спайк-тест (Spike Test): моделирует резкие кратковременные всплески нагрузки для анализа реакции системы на внезапные изменения.

    \item Тест выносливости (Soak Test): проводит длительное воздействие средних нагрузок, выявляя проблемы, связанные с утечками памяти и ухудшением производительности со временем.
\end{enumerate}
В рамках исследования особый интерес представляют сценарии, в которых паттерн будет иметь смысл например, при возникновении черезмерных нагрузок на сервис и возникновении его зависания. Выбраны два сценария:
\begin{enumerate}
    \item Нагрузочный тест: В данном сценарии постепенно растёт число виртуальных пользователей или запросов в секунду, что позволяет смоделировать возрастающую нагрузку, аналогичную пиковым периодам активности. При приближении к пределам пропускной способности системы могут возникать ошибки и увеличиваться время отклика. Circuit Breaker должен реагировать, чтобы предотвратить дальнейшие неудачные обращения к перегруженному микросервису. 

    \item Тест с увеличением размера запроса: Здесь фиксируется количество одновременных запросов, но постепенно увеличивается размер полезной нагрузки каждого запроса. Такой подход имитирует ситуацию, когда сервисы обрабатывают всё более сложные или объёмные сообщения, что может приводить к увеличению времени обработки, повышенной задержке или таймаутам. Circuit Breaker трактует накопление задержек и таймаутов как сигналы ухудшения качества сервиса и переключается в режим для защиты системы от перегрузки.
  \end{enumerate}
В микросервисной архитектуре запрос проходит через цепочку сервисов и функций, что требует детального мониторинга его маршрута и анализа задержек на каждом этапе. Трассировка позволяет выявить узкие места, определить причины ошибок и оптимизировать производительность системы. Распределённое трассирование собирает данные о каждом микросервисе, участвующем в обработке запроса, и позволяет восстановить полную картину: от времени обработки отдельных операций до момента возникновения таймаутов. Для реализации такой трассировки используются решения, среди которых популярны Jaeger, Zipkin и OpenTelemetry Collector.
    \begin{enumerate}
    \item Jaeger – система end-to-end трассировки, разработанная в Uber и поддерживаемая CNCF. Она собирает и визуализирует трассы, поддерживая различные модели хранения и масштабируясь под большие объёмы данных. Благодаря совместимости со стандартом OpenTelemetry, Jaeger легко интегрируется с разными языками и фреймворками. Модульная архитектура (агенты, коллекторы, веб-интерфейс) обеспечивает детальное отображение задержек, ошибок и зависимостей между сервисами, что делает его незаменимым инструментом для анализа распределённых систем.
    
    \item Zipkin, созданный в Twitter, также собирает трейс-спаны и предоставляет удобный веб-интерфейс для анализа. Он отличается простотой развертывания и использует формат B3 для передачи заголовков, что особенно удобно в экосистеме Spring Boot. Однако Zipkin менее оптимизирован для крупных инсталляций, что может ограничивать его применение в больших кластерах.
    
    \item OpenTelemetry Collector – универсальный агент, собирающий метрики, логи и трассы в разных форматах. Он не является самостоятельной системой визуализации, а служит посредником, отправляя данные в выбранное хранилище или систему анализа (например, Jaeger или Zipkin). Его главное преимущество – независимость от конкретного вендора и гибкость в настройке, что упрощает интеграцию с разными инструментами мониторинга.
    \end{enumerate}

    Учитывая поддержку стандарта OpenTelemetry, полноценную визуализацию, лёгкую интеграцию с Kubernetes/Istio и масштабируемость, для исследования выбрана система Jaeger как основное средство сбора трассировок и анализа задержек. Jaeger, обладая удобным веб-интерфейсом, превосходит альтернативные решения, обеспечивая надёжную основу для исследования метрик  и задержек в микросервисной архитектуре.


\section{Выводы}
\textbf{Аннотация.} \textit{Определены основные направления разработки и применения архитектурных паттернов для повышения отказоустойчивости микросервисов. Выполненный анализ показал эффективность паттернов Circuit Breaker и Bulkhead для предотвращения распространения сбоев. Сформулированы основные требования к использованию контейнерной оркестрации (Kubernetes) и service mesh (Istio, Linkerd, Consul Connect, Kuma), подчеркнута важность их совместного применения. Выполнено сравнение существующих решений service mesh, выявлены преимущества платформы Istio для сложных проектов. Показана необходимость практического тестирования отказоустойчивости, включая нагрузочные испытания, трассировку. Подчёркнута важность комплексного подхода, охватывающего проектирование, технологический стек и регулярную валидацию системы.}
В результате проведенного анализа можно подвести следующие итоги:
\begin{enumerate}
    \item Архитектурные паттерны повышают отказоустойчивость микросервисов. Анализ показал, что такие шаблоны, как Circuit Breaker и Bulkhead эффективно предотвращают распространение сбоев в распределённой системе. Circuit Breaker ограничивает каскадные ошибки, а Bulkhead не даёт одному сбойному компоненту исчерпать общие ресурсы системы. В совокупности эти и сопутствующие паттерны (Retry, Timeout, Fallback) значительно повышают надёжность сервисов.

    \item Контейнерная оркестрация и service mesh дополняют друг друга для обеспечения надёжности. Оркестратор обеспечивает автоматическое поддержание работы сервисов, создавая устойчивую основу исполнения. Service mesh добавляет уровень защиты на сетевом уровне, управляя межсервисными вызовами: от балансировки нагрузки до шифрования и механизмов отказоустойчивости. Совместное использование этих технологий позволяет достичь высокого уровня отказоустойчивости.

    \item Существующие реализации service mesh отличаются балансом функциональности и сложности. Сравнение сервисов продемонстрировало, что нет универсального решения: выбор mesh зависит от потребностей конкретного проекта. Istio предоставляет максимальный контроль над трафиком и безопасность, но предъявляет высокие требования к ресурсам и опыту эксплуатации. Linkerd прост и лёгок, оптимален для небольших команд и сценариев, где важны минимальные задержки. Consul полезен при гибридной инфраструктуре (объединение Kubernetes и традиционных сред), а Kuma – при мультикластерных развёртываниях. Для целей нашего исследования выбрано Istio как наиболее функционально насыщенная и популярная в индустрии.

    \item Тестирование отказоустойчивости требует имитации реальных условий нагрузки и сбоев. Нагрузочные тесты с помощью инструментов таких как k6 выявляют поведение системы на предельных режимах работы. Трассировка с помощью Jaeger даёт понимание, где возникают задержки или сбои в цепочке сервисов. 

\end{enumerate}
\section{Цели и задачи УИР}

\textbf{Аннотация} \textit{На основе проведенного анализа сформулирована цель учебно-исследовательской работы: разработать и экспериментально сравнить решения для обеспечения отказоустойчивости микросервисных приложений, реализованных на платформе Kubernetes, на основе паттерна Circuit Breaker.} 


Для достижения цели необходимо выполнить следующие задачи:
    \begin{enumerate}    
      \item \textbf{Создание экспериментальной инфраструктуры}
      \begin{enumerate}
        \item Разработка тестового микросервисного приложения с возможностью искусственного введения сбоев и задержек для моделирования различных сценариев отказов.
        \item Развёртывание кластера Kubernetes (K3s) и интеграция в него сервисной платформы Istio.
        \item Реализация конфигураций Istio, обеспечивающих применение паттерна Circuit Breaker (через правила DestinationRule).
        \item Развёртывание друго кластера Kubernetes (K3s) без использования service mesh.
        \item Написание Python библиотеки, реализовывающей Circuit Breaker паттерн и интеграция ее в код микросервисов.
        \item Внедрение системы распределённого трейсинга Jaeger.
        \item Настройка data collector для оценки состояния инфраструктуры и поведения системы при сбоях.
      \end{enumerate}
    
      \item \textbf{Экспериментальное исследование и тестирование}
      \begin{enumerate}
        \item Разработка и проведение нагрузочных тестов с использованием инструмента k6 для анализа производительности и отказоустойчивости системы при различных уровнях нагрузки и при активации механизмов Circuit Breaker.
        \item Эмуляция отказов компонентов приложения и сетевых задержек с помощью средств Istio Fault Injection с оценкой эффективности реагирования сервисов.
        \item Сбор и анализ трассировок Jaeger и метрик производительности системы (latency, throughput, доля ошибок, потребление ресурсов), для объективной оценки работы механизмов отказоустойчивости.
        \item Сравнение результатов работы системы в нескольких конфигурациях (без Istio, с Istio без Circuit Breaker, с Istio и Circuit Breaker) для количественного подтверждения влияния исследуемых подходов.
      \end{enumerate}
    
      \item \textbf{Анализ результатов и формулирование рекомендаций}
      \begin{enumerate}
        \item Интерпретация экспериментальных данных и оценка влияния service mesh (Istio) и паттерна Circuit Breaker на показатели отказоустойчивости микросервисного приложения.
        \item Сравнение эксперементальных  показателей задержек между самостоятельно реализованной библиотекой и Envoy proxy.
        \item Разработка практических рекомендаций по оптимальному использованию механизмов Circuit Breaker и сервисных сетей (service mesh), с выделением сценариев и условий, при которых их применение наиболее эффективно.
      \end{enumerate}
    \end{enumerate}

%%% Local Variables:
%%% TeX-engine: xetex
%%% eval: (setq-local TeX-master (concat "../" (seq-find (-cut string-match ".*-3-pz\.tex$" <>) (directory-files ".."))))
%%% End:
