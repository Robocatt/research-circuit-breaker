% \usepackage{longtable}
% \usepackage{tabularx}
% \usepackage{ltablex} 
\chapter{Аналитический обзор современных решений для обеспечения отказоустойчивости в микросервисных архитектурах.}
\label{chapter1}



%Большие отсупы --- это хорошо. Облегчает чтение длинных <<простыней>> текста
% \section{Общий анализ отказоустойчивости в микросервисах и паттернов}


В данном разделе обобщаются современные методы и инструменты, которые позволяют достичь высокой отказоустойчивости микросервисной архитектуры.
Рассматриваются характерные проблемы в надёжности распределённых сервисов и анализируются архитектурные паттерны, повышающие их устойчивость (в том числе Circuit Breaker, Bulkhead и др.).
Анализируются средства инфраструктуры - контейнеризация (Docker/Kubernetes) и сетевые решения (service mesh) – а также их роли в построении отказоустойчивых микросервисов.
Далее, проведён сравнительный обзор популярных реализаций service mesh: Istio, Linkerd, Consul, Kuma. Затем, описываются методы тестирования отказоустойчивости: инструменты для нагрузочного тестирования (k6), способы трассировки распределённых запросов (Jaeger).

\section{Анализ архитектурных паттернов, обеспечивающих отказоустойчивость.}

В микросервисной архитектуре отказ одного сервиса способен вызвать цепочку проблем во всей системе - эффект каскадного сбоя. Чтобы локализовать сбои и предотвратить их распространение, применяются паттерны отказоустойчивости. \textbf{Circuit Breaker} является одним из наиболее распространённых решений для повышения надёжности сервисов \cite{Newman2021}. Его идея позаимствована из электротехники: подобно автоматическому предохранителю, он разрывает цепь вызовов при обнаружении постоянных ошибок во взаимодействии сервисов. Реализация данного паттерна предусматривает мониторинг удалённых вызовов: если за заданный интервал накопилось определённое число неудач (исключений, таймаутов), Circuit Breaker переводится в состояние «Open» и начинает блокировать дальнейшие запросы к проблемному сервису, сразу возвращая ошибку или резервный ответ. Через некоторое время (период полуоткрытого состояния «Half-Open») пропускается пробный запрос, и при успешном ответе замыкается обратно (состояние «Closed»), возобновляя нормальную работу; если же ошибка сохраняется – цикл повторяется. Таким образом, данный паттерн позволяет избегать дополнительной нагрузки на зависимый сервис, давая ему время восстановиться, и сокращает время ожидания для потоков, обращающихся к недоступному ресурсу \cite{Punithavathy2024}. На практике, использование Circuit Breaker снижает риск обрушения всей системы из-за одного сбойного компонента.

Другим важным шаблоном является паттерн \textbf{Bulkhead}. Этот шаблон предлагает изолировать ресурсы для отдельных сервисов или групп запросов. Например, можно выделить независимые пулы потоков или подключений к базе данных для каждого микросервиса. В результате ошибка или задержка в одном компоненте приведет к потреблению ресурсов только своего пула и не сможет повлиять на всю систему. Паттерн bulkhead повышает устойчивость за счёт ограничения области воздействия сбоя: сбойный сервис исчерпает лишь свой выделенный лимит потоков/соединений, но остальные сервисы продолжат работать штатно \cite{IEEE2023}. На практике Bulkhead часто реализуется средствами контейнерной оркестрации или специальных библиотек – например, выделением отдельного пула потоков в контейнере для каждого клиента. В сочетании с Circuit Breaker, Bulkhead образует многослойную защиту: один паттерн быстро отсекает проблемные вызовы, а другой обеспечивает изоляцию ресурсов и предотвращает каскадное распространение отказов в системе, локализуя сбои и минимизируя их влияние на остальные компоненты. По данным исследований, паттерн Circuit Breaker способен снизить долю фатальных ошибок почти на 60\%, а Bulkhead повысить общую доступность сервисов примерно на 10\% \cite{IEEE2023}.

Помимо указанных двух паттернов, существуют другие способы повышения устойчивости архитектуры микросервисов. Часто применяется паттерн \textbf{Retry} (повторный запрос) --- автоматическая повторная попытка вызова внешнего сервиса при неудаче, обычно с экспоненциальной задержкой между попытками, чтобы не создать дополнительную нагрузку. Retry полезен при кратковременных сбоях (transient errors), но должен сочетаться с ограничением числа попыток и с Circuit Breaker, чтобы повторные вызовы не усугубляли ситуацию при длительной недоступности сервиса \cite{Punithavathy2024}. Ещё один важный механизм --- \textbf{Timeout} (таймауты на вызовы): если внешний запрос не отвечает за разумное время, он прерывается, что освобождает занятые ресурсы. В связке с таймаутами обычно используются Fallback-методы --- альтернативные действия при сбое внешнего сервиса (например, возврат кэшированного значения, дефолтного ответа, сообщения об ошибке). Такие меры позволяют системе завершаться аккуратно, без резкого отказа \cite{Nygard2018}.

Комплексное применение данных паттернов доказало свою эффективность на практике. В частности, опыты, проведённые корпорацией Netflix при внедрении библиотеки Hystrix, показали существенное снижение числа инцидентов, связанных с каскадными сбоями. Эти паттерны стали настолько важны, что современные фреймворки (например, Resilience4j для Java) и сервис-меш технологии (см. подраздел 1.2) поддерживают их «из коробки». Таким образом, архитектурные решения в виде Circuit Breaker, Bulkhead и сопутствующие им шаблоны (Retry, Timeout, Fallback) являются важнейшими компонентами обеспечения отказоустойчивости микросервисных приложений\cite{patternsraj}.

Паттерн Circuit Breaker является ключевым механизмом обеспечения отказоустойчивости микросервисной архитектуры, так как он своевременно обнаруживает сбои и локализует их, предотвращая цепную реакцию отказов в системе. Выбор этого паттерна для исследования обусловлен его доказанной эффективностью в снижении риска системных сбоев и возможности изолировать неисправные компоненты, что существенно повышает общую стабильность распределённых приложений. 

\section{Анализ возможностей контейнеризации для повышения надежности микросервисной архитектуры}

Контейнеризация и оркестрация внесли решающий вклад в повышение отказоустойчивости облачных приложений. Контейнеры предоставляют лёгковесную изоляцию сервисов, позволяя каждому микросервису работать в унифицированной среде с чётко определёнными зависимостями. Это снижает вероятность ошибок окружения и облегчает масштабирование. Более того, запуск сервиса в виде контейнера существенно ускоряет его перезапуск при сбое, позволяет автоматизировать повторный запуск.

Ключевым инструментом управления контейнеризированными микросервисами является Kubernetes – платформа оркестрации. Kubernetes автоматически следит за состоянием приложений и применяет стратегии self-healing (самовосстановления): при падении контейнера оркестратор перезапускает его, при отключении узла – переносит поды на работоспособные узлы, а при повышении нагрузки – может автоматически масштабировать реплики сервисов\cite{kuber}. Тем самым обеспечивается базовая устойчивость системы к аппаратным и программным сбоям без вмешательства администратора. Таким образом, оркестратор действует как «операционная система» для кластера, гарантируя, что заданное число экземпляров каждого сервиса всегда будет создано, несмотря на возможные локальные сбои. Существуют различные реализации Kubernetes. Для ресурсов с ограниченными вычислительными ресурсами разработаны облегчённые дистрибутивы Kubernetes, такие как \textbf{K3s}. Данная реализация представляет собой полностью совместимую с Kubernetes версию оркестратора, упакованную в один исполняемый файл размером менее 100 МБ \cite{mendezk3s}. Использование K3s позволяет вынести микросервисную инфраструктуру за пределы крупных датацентров, обеспечивая при этом механизмы отказоустойчивости Kubernetes в малых масштабах.

Однако одного механизма перезапуска сервисов недостаточно для комплексной надёжности: необходимо обеспечить устойчивость между сервисами, на уровне их взаимодействий. Для обеспечения такой устойчивости, была разработана концепция \textbf{service mesh}. Service mesh – это дополнительный коммуникационный слой поверх сетевого взаимодействия микросервисов. Он решает задачи обнаружения сервисов, балансировки нагрузки, шифрования трафика, а также реализации шаблонов устойчивости (таких как Сircuit breaker, Bulkhead см. подраздел 1.1) на уровне сети. Типичная архитектура service mesh включает \textit{data plane} (сетевые прокси рядом с каждым сервисом) и \textit{control plane} (централизованный диспетчер, управляющий правилами маршрутизации и сбора телеметрии). В результате каждый межсервисный вызов проходит через локальный прокси, который может выполнить необходимую логику. К примеру, на этом слое запрос может быть перенаправлен по другому маршруту, если основной сервис недоступен, соединение может быть дополнительно зашифровано, или реализован механизм прекращения связи с сервисом при повторяющихся неудачах (Сircuit breaker на уровне service mesh). Таким образом, применение mesh-инфраструктуры позволяет централизованно реализовать множество механизмов обеспечения надежности, которые в ином случае пришлось бы интегрировать непосредственно в код каждого отдельного сервиса. Исследования отмечают, что service mesh позволяет стандартизировать и упростить коммуникации: все вызовы проходят единообразную обработку, что снижает вероятность непредусмотренных отказов\cite{palavesam2025}. Примеры реализаций service mesh включают \textbf{Istio}, \textbf{Linkerd}, \textbf{Consul Connect} и \textbf{Kuma} (их сравнительный анализ приведён в подразделе 1.3). Общая цель у них одна – надёжная доставка запросов между микросервисами\cite{farkiani2022}, но подходы в реализации различаются.

Service mesh тесно интегрируется с оркестратором: например, в Kubernetes прокси-меш обычно развёртываются как sidecar-контейнеры внутри тех же подов, что и основные сервисы. Такая интеграция позволяет Kubernetes автоматически внедрять mesh-политику при масштабировании или перезапуске сервисов. Таким образом, наблюдается эффективное взаимодействие компонентов системы: Kubernetes обеспечивает физическую устойчивость функционирования сервисов (их запуск, перезапуск и распределение), а mesh-слой — логическую устойчивость коммуникаций посредством маршрутизации, повторных попыток и изоляции сбоев. Современные исследования подтверждают, что сочетание оркестрации и service mesh значительно повышает надёжность сложных распределенных архитектур\cite{palavesam2025}. Можно заключить, что для построения отказоустойчивых микросервисных систем требуется многоуровневый подход. Необходимо обеспечить устойчивость отдельных сервисов (за счёт контейнеризации и оркестрации), а также реализовать устойчивость их взаимодействия (за счёт service mesh).


\section{Анализ современных service mesh решений}


Разработчики, использующие Kubernetes для оркестрации, могут выбирать из нескольких open-source реализаций service mesh. Наиболее популярны следующие решения:

\begin{enumerate}
    \item \textbf{Istio} --- масштабируемый сервис-меш, изначально разработанный Google, IBM и RedHat (появился в 2017~г.). 
    
    \item \textbf{Linkerd} --- лёгкий mesh, ориентированный на простоту и высокую производительность. Изначально разработан компанией Buoyant, переписан на Rust.
    
    \item \textbf{Consul (Connect)} --- расширение популярной системы Consul от HashiCorp до полноценного service mesh. 
    
    \item \textbf{Kuma} --- относительно новое решение (разработано Kong Inc., выпущено в 2020~г.), позиционируемое как «универсальный сервис-меш». 
\end{enumerate}
Для более наглядного сравнения основных характеристик рассмотренных mesh-решений приведём обобщённую таблицу (табл.~\ref{tab:meshes}). Здесь сопоставляются функциональные возможности, требования и сферы применения Istio, Linkerd, Consul и Kuma.


\begingroup
\small
\setlength{\tabcolsep}{4pt} % Reduce column spacing
\begin{longtable}{|p{2.6cm}|p{3.3cm}|p{3.3cm}|p{3.3cm}|p{3.3cm}|}
\caption{Сравнение популярных service mesh для Kubernetes} \label{tab:meshes} \\
\hline
\textbf{Аспект} & \textbf{Istio} & \textbf{Linkerd} & \textbf{Consul Connect} & \textbf{Kuma} \\
\hline
\endfirsthead

\multicolumn{5}{c}{\tablename\ \thetable{} -- Продолжение} \\
\hline
\textbf{Аспект} & \textbf{Istio} & \textbf{Linkerd} & \textbf{Consul Connect} & \textbf{Kuma} \\
\hline
\endhead

\hline \multicolumn{5}{r}{{Продолжение на следующей странице}} \\
\endfoot

\hline
\endlastfoot

\textbf{Архитектура и прокси} & 
Envoy sidecar; контроллер Istiod. Модульная архитектура (Pilot, Mixer в ранних версиях) & 
Специальный лёгкий proxy (Linkerd2-proxy) на Rust; минималистичный контроллер. Монолитная архитектура. & 
Envoy sidecar (или собственный proxy), контроллер интегрирован в Consul server. Требует Consul-кластера. & 
Envoy sidecar; control-plane Kuma. Архитектура похожа на Istio, но проще \\
\hline

\textbf{Функционал и трафик} & 
Широкий: маршрутизация, балансировка, mirroring, fault injection, паттерны отказоустойчивости. Поддержка шлюзов ingress/egress. & 
Базовые возможности: load balancing, service discovery, mTLS. Ограниченная настройка маршрутов. & 
Широкие возможности service discovery (KV-хранилище). Traffic management присутствует, но менее гибкий, чем в Istio & 
Настройка трассировки, балансировки, маршрутизации, политики отказов, поддержка нескольких mesh. Мультизональность. \\
\hline

\textbf{Безопасность} & 
Полноценная инфраструктура: автовыдача сертификатов, mTLS, детальные настройки авторизации (RBAC, политики доступа) & 
mTLS по умолчанию для всех соединений. Нет встроенной сложной авторизации (интеграция с K8s RBAC) & 
mTLS через собственный CA Consul, гибкие политики «Intentions». Централизованное управление ACL & 
mTLS встроен (встроенный/внешний CA), политики доступа. Глобальные политики безопасности между зонами \\
\hline

\textbf{Произво\-ди\-тель\-ность} & 
Высокий overhead на Envoy proxy(CPU/память в 2–3 раза выше). Задержки под нагрузкой\cite{bremler2024performance}, хорошая масштабируемость & 
Минимальный overhead (быстрый proxy, мало ресурсов). Незначительные задержки. Эффективен при большом числе сервисов & 
Умеренные накладные расходы. Дополнительный ресурс на Consul-сервер. При >1000 сервисов Consul может стать узким местом & 
Сопоставимо с Istio. Контрольная плоскость лёгкая. Оптимизирован для распределённых сред \\
\hline

\textbf{Мульти\-клас\-тер\-ность
} & 
Поддерживается (multi-mesh/federation) — сложная настройка. Ориентирован на K8s; VM требуют доп. компонентов & 
Экспериментальное расширение Multi-Cluster. За пределами K8s не работает (только соединяет кластеры K8s) & 
Спроектирован для multi-datacenter. Легко соединяет кластеры и VM. Отличен для гибридных облаков & 
Концепция Zones: объединяет множество K8s-кластеров и других нод. Гибко работает в гибридных средах \\
\hline
\end{longtable}
\endgroup

Из таблицы видно, что \textbf{Istio} предлагает наибольшие возможности в плане управления трафиком и политик, но в то же время требует больше ресурсов и усилий на сопровождение. \textbf{Linkerd} наиболее лёгок и прост, что делает его оптимальным для небольших команд или в ситуациях, где дополнительные возможности mesh не столь востребованы. \textbf{Consul} выгодно отличается способностью соединять разные среды (не только Kubernetes), однако добавляет сложность развёртывания отдельного Consul-кластера. \textbf{Kuma} стремится сочетать преимущества обоих подходов – универсальность Consul с относительной простотой Linkerd.

В контексте данной работы выбор сделан в пользу \textbf{Istio}. Во-первых, как отмечается в исследованиях, Istio остаётся наиболее функционально насыщенной и гибкой платформой \cite{palavesam2025}, которая особенно эффективна в крупных масштабируемых системах. Во-вторых, нас интересует реализация паттерна Circuit Breaker и других механизмов отказоустойчивости на уровне service mesh – Istio предоставляет развитые средства для этого. Таким образом, несмотря на издержки в сложности, Istio представляется оптимальным выбором для изучения и реализации отказоустойчивой микросервисной архитектуры с использованием Kubernetes.

\section{Анализ инструментов и типов тестирования микросервисных архитектур.}
\label{sec:test-analysis}

Нагрузочное тестирование микросервисов можно проводить с помощью различных open-source инструментов, среди которых Gatling, Locust, k6 и др. Каждый из них имеет свои преимущества и недостатки, которые стоит учитывать при выборе для тестирования.
\begin{enumerate}
\item Gatling\cite{gatling} – высокопроизводительный инструмент для тестирования, разработанный на Scala. Он эффективно генерирует нагрузку даже при тысячах виртуальных пользователей, сохраняя низкую нагрузку на саму систему тестирования. Детализированные отчёты и графики помогают проводить глубокий анализ результатов. Недостатком является необходимость знания Scala и функционального программирования.

\item Locust \cite{locust} – инструмент на Python, который позволяет описывать сценарии тестирования с использованием асинхронного подхода. Это делает его масштабируемым и гибким: поведение пользователей можно задавать программно, что удобно для сложных сценариев \cite{allam2024synthetictimeseriesanomaly}. Интеграция с CI/CD и возможность распределённых тестов – дополнительные плюсы. Однако встроенные средства визуализации менее развиты, и для полноценного анализа результатов могут потребоваться дополнительные инструменты.

\item k6\cite{k6} – современный инструмент для тестирования API и микросервисов, реализованный на Go с использованием JavaScript для описания сценариев. Он характеризуется низкими накладными расходами и эффективным использованием ресурсов, что позволяет генерировать значительную нагрузку. Прямая интеграция с системами мониторингаи возможность автоматизированного запуска в CI/CD делают его привлекательным для современных веб-сервисов. Основное ограничение – поддержка в основном HTTP/HTTPS и WebSocket, что может не подойти для тестирования специфических протоколов.
\end{enumerate}
Проанализировав перечисленные решения, в данном исследовании выбор сделан в пользу k6 как основного инструмента нагрузочного тестирования. Это обусловлено несколькими факторами. Во-первых, написание сценариев на JavaScript упрощают разработку тестов. Во-вторых, низкая нагрузка самого инструмента на систему позволяет проводить более чистые эксперименты. В-третьих, он уже применялся в научных работах для анализа микросервисных архитектур. \cite{aqasizade2024kubernetesactionexploringperformance}

Нагрузочное тестирование включает несколько типов тестов, каждое из которых позволяет оценить разные аспекты производительности системы. К основным относятся:
\begin{enumerate}
    \item Нагрузочный тест (Load Test)\cite{Waseem_2021}: проверяет работу сервиса при постепенном увеличении числа запросов или виртуальных пользователей, моделируя реальный рост трафика.

    \item Стресс-тест (Stress Test): определяет пределы устойчивости системы, подвергая её нагрузке, значительно превышающей номинальную.

    \item Спайк-тест (Spike Test): моделирует резкие кратковременные всплески нагрузки для анализа реакции системы на внезапные изменения.

    \item Тест выносливости (Soak Test): проводит длительное воздействие средних нагрузок, выявляя проблемы, связанные с утечками памяти и ухудшением производительности со временем.
\end{enumerate}
В рамках исследования особый интерес представляют сценарии, в которых паттерн будет иметь смысл например, при возникновении черезмерных нагрузок на сервис и возникновении его зависания. Выбраны два сценария:
\begin{enumerate}
    \item Нагрузочный тест: В данном сценарии постепенно растёт число виртуальных пользователей или запросов в секунду, что позволяет смоделировать возрастающую нагрузку, аналогичную пиковым периодам активности. При приближении к пределам пропускной способности системы могут возникать ошибки и увеличиваться время отклика. Circuit Breaker должен реагировать, чтобы предотвратить дальнейшие неудачные обращения к перегруженному микросервису. 

    \item Тест с увеличением размера запроса: Здесь фиксируется количество одновременных запросов, но постепенно увеличивается размер полезной нагрузки каждого запроса. Такой подход имитирует ситуацию, когда сервисы обрабатывают всё более сложные или объёмные сообщения, что может приводить к увеличению времени обработки, повышенной задержке или таймаутам. Circuit Breaker трактует накопление задержек и таймаутов как сигналы ухудшения качества сервиса и переключается в режим для защиты системы от перегрузки.
  \end{enumerate}
В микросервисной архитектуре запрос проходит через цепочку сервисов и функций, что требует детального мониторинга его маршрута и анализа задержек на каждом этапе. Трассировка позволяет выявить узкие места, определить причины ошибок и оптимизировать производительность системы. Распределённое трассирование собирает данные о каждом микросервисе, участвующем в обработке запроса, и позволяет отследить все стадии прохождения запроса - от времени обработки отдельных операций до момента возникновения таймаутов. Для реализации такой трассировки используются решения, среди которых популярны Jaeger, Zipkin и OpenTelemetry Collector.
    \begin{enumerate}
    \item Jaeger\cite{jaeger} – система end-to-end трассировки, разработанная в Uber и поддерживаемая CNCF. Она собирает и визуализирует трассы, поддерживая различные модели хранения и масштабируясь под большие объёмы данных. Благодаря совместимости со стандартом OpenTelemetry, Jaeger легко интегрируется с разными языками и фреймворками. Модульная архитектура (агенты, коллекторы, веб-интерфейс) обеспечивает детальное отображение задержек, ошибок и зависимостей между сервисами, что делает его незаменимым инструментом для анализа распределённых систем.
    
    \item Zipkin\cite{Zipkin}, созданный в Twitter, также собирает трейс-спаны и предоставляет удобный веб-интерфейс для анализа. Он отличается простотой развертывания и использует формат B3 для передачи заголовков, что особенно удобно в экосистеме Spring Boot. Однако Zipkin менее оптимизирован для крупных инсталляций, что может ограничивать его применение в больших кластерах\cite{Borges_2021}.
    
    \item OpenTelemetry Collector\cite{otelcollector} – универсальный агент, собирающий метрики, логи и трассы в разных форматах. Он не является самостоятельной системой визуализации, а служит посредником, отправляя данные в выбранное хранилище или систему анализа (например, Jaeger или Zipkin). Его главное преимущество – независимость от конкретного вендора и гибкость в настройке, что упрощает интеграцию с разными инструментами мониторинга.
    \end{enumerate}

    Учитывая поддержку стандарта OpenTelemetry, полноценную визуализацию, лёгкую интеграцию с Kubernetes/Istio и масштабируемость, для исследования выбрана система Jaeger как основное средство сбора трассировок и анализа задержек. Jaeger, обладая удобным веб-интерфейсом, превосходит альтернативные решения, обеспечивая надёжную основу для исследования метрик  и задержек в микросервисной архитектуре.


\section{Выводы}

В результате проведенного анализа можно подвести следующие итоги:
\begin{enumerate}
    \item Анализ показал, что такие шаблоны, как Circuit Breaker и Bulkhead эффективно предотвращают распространение сбоев в распределённой системе. Circuit Breaker ограничивает каскадные ошибки, а Bulkhead не даёт одному сбойному компоненту исчерпать общие ресурсы системы. Circuit Breaker выбран для исследования из-за его распространённости, а так же проверенной способности снижать вероятность системных сбоев.

    \item Оркестратор обеспечивает автоматическое поддержание работы сервисов, создавая устойчивую основу исполнения. Service mesh добавляет уровень защиты на сетевом уровне, управляя межсервисными вызовами: от балансировки нагрузки до шифрования и механизмов отказоустойчивости. Совместное использование этих технологий позволяет достичь высокого уровня отказоустойчивости.

    \item Существующие реализации service mesh отличаются балансом функциональности и сложности. Сравнение сервисов (Istio, Linkerd, Consul, Kuma) продемонстрировало, что нет универсального решения: выбор mesh зависит от потребностей конкретного проекта. Для целей нашего исследования выбрано Istio как наиболее функционально насыщенная и популярная в индустрии.

    \item Нагрузочные тесты с помощью k6 выявляют поведение системы на предельных режимах работы и эффективны для проведения анализа времени работы системы. Трассировка с помощью Jaeger даёт понимание, где возникают задержки или сбои в цепочке сервисов. Промежуточный сборщик логов и трейсов позволяет ассинхронно работать с данными.

\end{enumerate}
\section{Цели и задачи УИР}


Для достижения цели необходимо выполнить следующие задачи:
    \begin{enumerate}    
      \item \textbf{Создание экспериментальной инфраструктуры}
      \begin{enumerate}
        \item Разработка тестового микросервисного приложения с возможностью искусственного введения сбоев и задержек для моделирования различных сценариев отказов.
        \item Развёртывание кластера Kubernetes (K3s) и интеграция в него сервисной платформы Istio.
        \item Реализация конфигураций Istio, обеспечивающих применение паттерна Circuit Breaker (через правила DestinationRule).
        \item Развёртывание друго кластера Kubernetes (K3s) без использования service mesh.
        \item Написание Python библиотеки, реализовывающей Circuit Breaker паттерн и интеграция ее в код микросервисов.
        \item Внедрение системы распределённого трейсинга Jaeger.
        \item Настройка data collector для оценки состояния инфраструктуры и поведения системы при сбоях.
      \end{enumerate}
    
      \item \textbf{Экспериментальное исследование и тестирование}
      \begin{enumerate}
        \item Разработка и проведение нагрузочных тестов с использованием инструмента k6 для анализа производительности и отказоустойчивости системы при различных уровнях нагрузки и при активации механизмов Circuit Breaker.
        \item Эмуляция отказов компонентов приложения и сетевых задержек с помощью средств Istio Fault Injection с оценкой эффективности реагирования сервисов.
        \item Сбор и анализ трассировок Jaeger и метрик производительности системы (latency, throughput, доля ошибок, потребление ресурсов), для объективной оценки работы механизмов отказоустойчивости.
        \item Сравнение результатов работы системы в нескольких конфигурациях (без Istio, с Istio без Circuit Breaker, с Istio и Circuit Breaker) для количественного подтверждения влияния исследуемых подходов.
      \end{enumerate}
    
      \item \textbf{Анализ результатов и формулирование рекомендаций}
      \begin{enumerate}
        \item Интерпретация экспериментальных данных и оценка влияния service mesh (Istio) и паттерна Circuit Breaker на показатели отказоустойчивости микросервисного приложения.
        \item Сравнение эксперементальных  показателей задержек между самостоятельно реализованной библиотекой и Envoy proxy.
        \item Разработка практических рекомендаций по оптимальному использованию механизмов Circuit Breaker и сервисных сетей (service mesh), с выделением сценариев и условий, при которых их применение наиболее эффективно.
      \end{enumerate}
    \end{enumerate}

%%% Local Variables:
%%% TeX-engine: xetex
%%% eval: (setq-local TeX-master (concat "../" (seq-find (-cut string-match ".*-3-pz\.tex$" <>) (directory-files ".."))))
%%% End:
